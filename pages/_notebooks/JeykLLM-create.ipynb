{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bamr87/it-journey/blob/master/pages/_notebooks/JeykLLM-create.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thsr_GIPbuvy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIPZi2Iubuvy"
      },
      "source": [
        "---\n",
        "title: \"Chat GPT Text Generation\"\n",
        "description: \"This notebook demonstrates how to use the Chat GPT model for text generation.\"\n",
        "tags: [\"NLP\", \"GPT\", \"Text Generation\"]\n",
        "libraries:\n",
        "  - openai\n",
        "  - python-dotenv\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gr4zftibuvy"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to use the Chat GPT model for text generation. Chat GPT is a variant of the GPT model that is fine-tuned on conversational data. This makes it particularly well-suited for generating conversational text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HGGs6aXbuvy"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, we install the `openai` and `python-dotenv` libraries.\n",
        "\n",
        "The `openai` library is an official Python client for the OpenAI API. We will use this library to interact with the Chat GPT model.\n",
        "\n",
        "The `python-dotenv` library is used to load environment variables from a `.env` file. We will use this library to load our OpenAI API key from a `.env` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6YZmVwd3buvy",
        "outputId": "49f49596-5c49-444b-a326-6ede24c4db64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: openai\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n",
            "\u001b[33mWARNING: Package(s) not found: python-dotenv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "# Pre-requisites\n",
        "!pip show openai || pip install openai\n",
        "!pip show python-dotenv || pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIG6kAzJbuvz"
      },
      "source": [
        "## Setting up the OpenAI API Key\n",
        "\n",
        "To use the OpenAI API, you need to sign up for an API key. You can get your API key by creating an account on the OpenAI website.\n",
        "\n",
        "Once you have your API keys, create a `.env` file in the same directory as this notebook and add the following lines with your key values:\n",
        "\n",
        "```shell\n",
        "OPENAI_API_KEY=YOUR_API_KEY # should strat with 'sk-'\n",
        "PROJECT_ID=YOUR_PROJECT_ID  # should start with 'pro-'\n",
        "ORG_ID=YOUR_ORG_ID          # should start with 'org-'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Or Setup your keys in COLAB"
      ],
      "metadata": {
        "id": "uZnQXhLCdqsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key=userdata.get('OPENAI_API_KEY')\n",
        "project_id=userdata.get('PROJECT_ID')\n",
        "org_id=userdata.get('ORG_ID')"
      ],
      "metadata": {
        "id": "esRRkypmckOG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SrijdwzQbuvz",
        "outputId": "e61e6d03-533f-4b56-e5d9-64bc1900bbe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load environment variables.\n",
            "Failed to load OPENAI_API_KEY.\n",
            "Failed to load PROJECT_ID.\n",
            "Failed to load ORG_ID.\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "if load_dotenv():\n",
        "    print(\"Environment variables loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load environment variables.\")\n",
        "\n",
        "# Get API key from environment variables\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if api_key:\n",
        "    print(\"OPENAI_API_KEY loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load OPENAI_API_KEY.\")\n",
        "\n",
        "# Get project ID from environment variables\n",
        "project_id = os.getenv('PROJECT_ID')\n",
        "if project_id:\n",
        "    print(\"PROJECT_ID loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load PROJECT_ID.\")\n",
        "\n",
        "# Get organization ID from environment variables\n",
        "org_id = os.getenv('ORG_ID')\n",
        "if org_id:\n",
        "    print(\"ORG_ID loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load ORG_ID.\")\n"
      ]
    },
    {
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Get API key from Google Colab userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "if api_key:\n",
        "    print(\"OPENAI_API_KEY loaded successfully from Google Colab.\")\n",
        "else:\n",
        "    print(\"Failed to load OPENAI_API_KEY from Google Colab.\")\n",
        "\n",
        "# Get project ID from Google Colab userdata\n",
        "project_id = userdata.get('PROJECT_ID')\n",
        "if project_id:\n",
        "    print(\"PROJECT_ID loaded successfully from Google Colab.\")\n",
        "else:\n",
        "    print(\"Failed to load PROJECT_ID from Google Colab.\")\n",
        "\n",
        "# Get organization ID from Google Colab userdata\n",
        "org_id = userdata.get('ORG_ID')\n",
        "if org_id:\n",
        "    print(\"ORG_ID loaded successfully from Google Colab.\")\n",
        "else:\n",
        "    print(\"Failed to load ORG_ID from Google Colab.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kufVkX10e5kU",
        "outputId": "2f767fe4-acdd-4388-8969-71d5cae0d7fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY loaded successfully from Google Colab.\n",
            "PROJECT_ID loaded successfully from Google Colab.\n",
            "ORG_ID loaded successfully from Google Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlAfxk8gbuvz"
      },
      "source": [
        "## Checking the Environment Variables\n",
        "\n",
        "To check if the environment variables are loaded correctly, we will print the API key's first and last 4 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZms7Ahdbuvz",
        "outputId": "e421e1d0-193c-4907-af67-2b00196d2b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY:  sk-p...RbaA\n",
            "PROJECT_ID:  proj...OeP3\n",
            "ORG_ID:  org-...1j1N\n"
          ]
        }
      ],
      "source": [
        "# Print the loaded values with only a snippet for security\n",
        "print(\"OPENAI_API_KEY: \", api_key[:4] + \"...\" + api_key[-4:])\n",
        "print(\"PROJECT_ID: \", project_id[:4] + \"...\" + project_id[-4:])\n",
        "print(\"ORG_ID: \", org_id[:4] + \"...\" + org_id[-4:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc4sMdbrbuvz"
      },
      "source": [
        "## Test the connection with OpenAI API\n",
        "\n",
        "We will test the connection with the OpenAI API by calling the `openai.ChatCompletion.create` method with a simple prompt.\n"
      ]
    },
    {
      "source": [
        "from openai import OpenAI\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "\n",
        "# Use the api_key variable directly instead of os.getenv()\n",
        "client = OpenAI(\n",
        "  organization=org_id, # Use the org_id variable\n",
        "  project=project_id, # Use the project_id variable\n",
        "  api_key = api_key # Use the api_key variable\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "m6Wf8vdCfX9A",
        "outputId": "d3a25da9-1784-4f5c-8e58-dffba527317d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqZHkwbrbuvz"
      },
      "source": [
        "## Define the function to create an Assistant\n",
        "\n",
        "We will create a function to create an assistant by calling the `client.beta.assistants.create` method with instructions and a name as parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "q41rbG2jbuvz"
      },
      "outputs": [],
      "source": [
        "def create_assistant(name, instructions):\n",
        "    assistant = client.beta.assistants.create(\n",
        "        name=name,\n",
        "        instructions=instructions,\n",
        "        model=\"gpt-4o\",\n",
        "    )\n",
        "    return assistant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDIzcfUcbuvz"
      },
      "source": [
        "## Invoke the function to create an Assistant\n",
        "\n",
        "Finally, we will create an assistant by calling the `create_assistant` function with instructions and a name as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PS2RCb86buvz"
      },
      "outputs": [],
      "source": [
        "# Define the name\n",
        "assistant_name = \"Title Generator\"\n",
        "\n",
        "# Define the instructions\n",
        "instructions= \"Your job is to take content and output a 4-word title that summarizes the content in a thought provoking manner. The title should be intriguing and attention getting for a reader. In other words, try to make it a worth while title for someone to be interested in.\"\n",
        "\n",
        "# Create the assistant\n",
        "assistant = create_assistant(assistant_name, instructions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj9Mdkn1buvz"
      },
      "source": [
        "## Verify the Assistant\n",
        "\n",
        "Print the assistant details to verify if the assistant is created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "soLvK0jxbuvz",
        "outputId": "2bcad528-8071-41df-efc3-c64d64b53923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asst_sfgvtibmM6lc0eiINkNUCGLs\n",
            "gpt-4o\n",
            "Your job is to take content and output a 4-word title that summarizes the content in a thought provoking manner. The title should be intriguing and attention getting for a reader. In other words, try to make it a worth while title for someone to be interested in.\n",
            "Title Generator\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Print the assistant ID\n",
        "print(assistant.id)\n",
        "print(assistant.model)\n",
        "print(assistant.instructions)\n",
        "print(assistant.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N65BV1Zibuvz"
      },
      "source": [
        "## Define the function to send a message to the Assistant\n",
        "\n",
        "We will create a function to send a message to the assistant by calling the `client.beta.assistants.message.create` method with the assistant id and message as parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgy1S0VNbuv0"
      },
      "source": [
        "## Generating Text with Chat GPT\n",
        "\n",
        "Next, we will create a function to generate text using the Chat GPT model by calling the `openai.ChatCompletion.create` method with a prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vCHQFEQdbuv0"
      },
      "outputs": [],
      "source": [
        "def generate_content(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "    # Get the content of the last message in the response\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQM4cyZWbuv0"
      },
      "source": [
        "## Generate Text\n",
        "\n",
        "Finally, we will generate text using the Chat GPT model by calling the `generate_content` function with a prompt as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DNacDXtjbuv0",
        "outputId": "1dc1915e-45f7-4a33-bda8-d42723e387e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your prompt for the GPT: Tell me a really bad dad joke that is long, and ends with useless wisdom. \n"
          ]
        }
      ],
      "source": [
        "# Get the prompt from the user\n",
        "prompt = input(\"Please enter your prompt for the GPT: \")\n",
        "content = generate_content(prompt)\n",
        "\n",
        "# write me a satirical article about a company with good intentions to help poor countires irrigate their dessert land but only to have their equipment fail and polute the land that was intended to be used to grow wheat. Eventually, the cost to grow wheat increased and the water supply became polluted, which sparked a revolution and stance against western imperialism.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYJ0JFhGbuv0"
      },
      "source": [
        "## Print the generated text\n",
        "\n",
        "Print the generated text to see the output of the Chat GPT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "48lZsoRkbuv0",
        "outputId": "fe4ef7bf-b2db-460f-8313-ca5e027f0d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the scarecrow win an award?\n",
            "\n",
            "Because he was outstanding in his field!\n",
            "\n",
            "Remember, it's always a good idea to plant your corn in rows, but your jokes should never be corny!\n"
          ]
        }
      ],
      "source": [
        "# Print the generated content\n",
        "print(content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvLGpXTPbuv0"
      },
      "source": [
        "## Define the function to create a message for the Assistant\n",
        "\n",
        "This function will create a thread message for the assistant by calling the `client.beta.threads.create()` with the content as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WSjiU2CDbuv0"
      },
      "outputs": [],
      "source": [
        "def create_message(content):\n",
        "    thread = client.beta.threads.create()\n",
        "    message = client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=content\n",
        "    )\n",
        "    return message\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aHWg8b3buv0"
      },
      "source": [
        "## Invoke the function to create a message for the Assistant\n",
        "\n",
        "Finally, we will create a message for the assistant by calling the `create_message` function with the content as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v4qotGDxbuv0",
        "outputId": "b87ce200-7fec-4f41-ba89-6a7effff73bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'content' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-31bdd0ef0914>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ],
      "source": [
        "message = create_message(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KejlxHY9buv0"
      },
      "source": [
        "Print the message details to verify if the message is created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrPphLBIbuv0",
        "outputId": "620b4b4b-20bb-40f1-9a77-ce3faa788b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thread_hC5bIvln7hYrocJsAPBOlLfa\n",
            "msg_c6HwS5Qqeu3ARdEiyhUzqgVh\n",
            "In a classic case of good intentions gone awry, the company \"AquaAid\" embarked on a mission to help impoverished desert countries irrigate their arid lands and transform them into fertile wheat fields. With grand promises of ending hunger and poverty, AquaAid brought in state-of-the-art irrigation equipment and set to work in the vast desert landscapes.\n",
            "\n",
            "But oh, how the tides turned against them! It was as if Murphy's Law had taken full effect - anything that could go wrong, did go wrong. The supposedly cutting-edge equipment malfunctioned almost immediately, causing vast stretches of once barren land to be tainted with pollutants and toxic chemicals. What was meant to be a beacon of hope for the struggling nations quickly turned into a nightmare, as the contaminated water and soil made it impossible to grow anything edible.\n",
            "\n",
            "As the cost of growing wheat skyrocketed and the promised abundance of food remained a distant dream, the people of the affected countries began to see AquaAid not as benevolent saviors, but as agents of destruction. Anti-western sentiment grew rampant as accusations of imperialism and exploitation were hurled at the now beleaguered company.\n",
            "\n",
            "Protests flared up, with angry mobs denouncing AquaAid and demanding immediate retribution for their ruined lands and shattered dreams. The once barren deserts were now teeming not with life-giving wheat, but with rebellion and dissent.\n",
            "\n",
            "In a tragic turn of events, what was meant to be a noble endeavor to aid the less fortunate had spiraled into a grotesque display of corporate greed and incompetence. AquaAid had unwittingly sown the seeds of revolution, leaving a legacy of polluted waters and broken promises in its wake.\n",
            "\n",
            "And so, as the sun set on the desolate desert lands, the tale of AquaAid served as a cautionary reminder of the perils of good intentions gone astray, and a sobering lesson on the dangers of playing god in foreign lands. May we all learn from their folly, and strive to do better in our efforts to aid those in need.\n"
          ]
        }
      ],
      "source": [
        "print(message.thread_id)\n",
        "print(message.id)\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjhPQLqbbuv0"
      },
      "source": [
        "## Define the function to run the thread for the Assistant\n",
        "\n",
        "This function will run the thread for the assistant created earlier. It will call the `client.beta.threads.runs.create_and_poll()` with the assistant id and thread id as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si2v0S_7buv0"
      },
      "outputs": [],
      "source": [
        "def create_and_poll_run(thread_id, assistant_id):\n",
        "  run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread_id,\n",
        "    assistant_id=assistant_id,\n",
        "  )\n",
        "  return run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfJozDGMbuv0"
      },
      "source": [
        "## Run the thread for the Assistant\n",
        "\n",
        "Finally, we will run the thread for the assistant by calling the `run_thread` function with the assistant id and thread id as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iclZtPDybuv0"
      },
      "outputs": [],
      "source": [
        "\n",
        "thread_id = message.thread_id\n",
        "assistant_id = assistant.id\n",
        "run = create_and_poll_run(thread_id, assistant_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkPIzvybuv0"
      },
      "source": [
        "## Check the thread status\n",
        "\n",
        "Print the thread details to verify if the thread is running successfully. and return the title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32aA-mvTbuv0",
        "outputId": "36770fb6-d964-4617-f635-bc5e9db23d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AquaAid's Devastating Desert Mission\n"
          ]
        }
      ],
      "source": [
        "if run.status == 'completed':\n",
        "  messages = client.beta.threads.messages.list(\n",
        "    thread_id=message.thread_id\n",
        "  )\n",
        "  text_message = messages.data[0].content[0].text.value\n",
        "  title = text_message\n",
        "  print(title)\n",
        "else:\n",
        "  print(run.status)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsSk9i6Fbuv0"
      },
      "source": [
        "## Define the Markdown file generation function for Jekyll\n",
        "\n",
        "Finally, we will generate the markdown file with the generated text and thread title. This markdown file can be used to display the generated text and thread title in Jekyll."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MEiwRJebuv0"
      },
      "outputs": [],
      "source": [
        "def create_jekyll_post(title, content):\n",
        "    front_matter = {\n",
        "        'title': title,\n",
        "        'layout': 'journals',\n",
        "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'categories': 'gpt',\n",
        "        'prompt': prompt,\n",
        "        'assistant': assistant_name,\n",
        "    }\n",
        "    post_content = f\"---\\n{yaml.dump(front_matter)}---\\n{content}\"\n",
        "    filename = f\"../_posts/{datetime.now().strftime('%Y-%m-%d')}-{title.lower().replace(' ', '-')}.md\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(post_content)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhjwcMDNbuv0"
      },
      "source": [
        "## Run the Markdown file generation function\n",
        "\n",
        "Finally, we will run the `create_jekyll_post` function to generate the markdown file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpjMSZpsbuv4",
        "outputId": "485926cf-56b8-4a23-a75a-69331dbd82db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The new file is created at: ../_posts/2024-06-18-aquaaid's-devastating-desert-mission.md\n"
          ]
        }
      ],
      "source": [
        "file_path = create_jekyll_post(title, content)\n",
        "print(f\"The new file is created at: {file_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}